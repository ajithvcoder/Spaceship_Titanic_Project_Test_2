import os 
import urllib.request as request
import zipfile
from titanicSpaceShip import logger
from titanicSpaceShip.utils.common import get_size
from titanicSpaceShip.entity.config_entity import DataIngestionConfig
import time
import csv
from pathlib import Path
from cassandra.cluster import Cluster
from cassandra.auth import PlainTextAuthProvider
import json

class DataIngestion:
    def __init__(self, config: DataIngestionConfig):
        self.config = config
    
    def download_file(self):
        delay = 5
        max_retries = 1
        for _ in range(max_retries):
            try:
                if not os.path.exists(self.config.local_data_file):
                    # This secure connect bundle is autogenerated when you download your SCB, 
                    # if yours is different update the file name below
                    cloud_config= {
                    'secure_connect_bundle': self.config.cloud_config_zipfile
                    }
                    # This token JSON file is autogenerated when you download your token, 
                    # if yours is different update the file name below
                    with open(self.config.authentication_token) as f:
                        secrets = json.load(f)
                    CLIENT_ID = secrets["clientId"]
                    CLIENT_SECRET = secrets["secret"]

                    auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)
                    cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)
                    session = cluster.connect()

                    row = session.execute('SELECT * FROM "prediction"."data"')
                    if row:
                        # Specify the CSV file path
                        csv_file_path = self.config.local_data_file

                        # Write named tuples to CSV file
                        with open(csv_file_path, 'w', newline='') as csv_file:
                            writer = csv.writer(csv_file)
                            
                            # Write header
                            writer.writerow(row[0]._fields)
                            
                            # Write data
                            for each in row:
                                writer.writerow(each)
                            logger.info(f"{self.config.local_data_file} download! from astra db with following info: \n {row[0]._fields}")
                    else:
                        logger.info(f"An Error occurred while connecting to db")
                    
                else:
                    logger.info(f"File already exists of size: {get_size(Path(self.config.local_data_file))}")
            except Exception as e:
                logger.info(f"Delay for next attempt {e}")
                time.sleep(delay)
                delay *= 2
        else:
            logger.info(f"Failed connecting to astra/casandra db after {max_retries} attempt")

def decodeData(data) -> dict:
    decodedFeatures = {}
    for key, val in data.items():
        if key in ['Age','RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']:
            val = [float(val[0])]
        elif key in ["CryoSleep", "VIP"]:
            val = [val[0]]
        decodedFeatures[key] = val
    logger.info("data was decoded")
    return decodedFeatures